{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Mean: [0.4913996756076813, 0.4821584224700928, 0.44653090834617615] Std: [0.24703224003314972, 0.24348513782024384, 0.26158785820007324]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "lr = 0.1\n",
    "\n",
    "data_dir = \"/home/studio-lab-user/CIL_Survey/data\"\n",
    "train_dataset_gpu = {}\n",
    "eval_dataset_gpu = {}\n",
    "\n",
    "# dataset\n",
    "train = torchvision.datasets.CIFAR10(root=data_dir, download=True, transform=transforms.ToTensor())\n",
    "eval = torchvision.datasets.CIFAR10(root=data_dir, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# dataloaders\n",
    "train_dataset_gpu_loader = torch.utils.data.DataLoader(train, batch_size=len(train), drop_last=True,\n",
    "                                            shuffle=True, num_workers=2, persistent_workers=False)\n",
    "eval_dataset_gpu_loader = torch.utils.data.DataLoader(eval, batch_size=len(eval), drop_last=True,\n",
    "                                            shuffle=False, num_workers=1, persistent_workers=False)\n",
    "\n",
    "# move dataset to gpu\n",
    "train_dataset_gpu['images'], train_dataset_gpu['targets'] = [item.to(device=\"cuda\", non_blocking=True) for item in next(iter(train_dataset_gpu_loader))]\n",
    "eval_dataset_gpu['images'],  eval_dataset_gpu['targets']  = [item.to(device=\"cuda\", non_blocking=True) for item in next(iter(eval_dataset_gpu_loader)) ]\n",
    "\n",
    "# normalization\n",
    "train_cifar10_std, train_cifar10_mean = torch.std_mean(train_dataset_gpu['images'], dim=(0, 2, 3)) \n",
    "print(f\"Mean: {train_cifar10_mean.tolist()}\", f\"Std: {train_cifar10_std.tolist()}\")\n",
    "def batch_normalize_images(input_images, mean, std):\n",
    "    return (input_images - mean.view(1, -1, 1, 1)) / std.view(1, -1, 1, 1)\n",
    "batch_normalize_images = partial(batch_normalize_images, mean=train_cifar10_mean, std=train_cifar10_std)\n",
    "train_dataset_gpu['images'] = batch_normalize_images(train_dataset_gpu['images'])\n",
    "eval_dataset_gpu['images']  = batch_normalize_images(eval_dataset_gpu['images'])\n",
    "\n",
    "data = {\n",
    "        'train': train_dataset_gpu,\n",
    "        'eval': eval_dataset_gpu\n",
    "    }\n",
    "\n",
    "## Uncomfortable shorthand, but basically we pad evenly on all _4_ sides with the pad_amount specified in the original dictionary\n",
    "pad_amount = 4\n",
    "data['train']['images'] = F.pad(data['train']['images'], (pad_amount,)*4, 'reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms are:\n",
    "# random crop\n",
    "# random hotizontal flip\n",
    "\n",
    "net = torchvision.models.resnet18()\n",
    "net.fc = nn.Linear(512, 10, bias=True)\n",
    "net.to(device);  # TODO: Look into memory_format param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is actually (I believe) a pretty clean implementation of how to do something like this, since shifted-square masks unique to each depth-channel can actually be rather\n",
    "## tricky in practice. That said, if there's a better way, please do feel free to submit it! This can be one of the harder parts of the code to understand (though I personally get\n",
    "## stuck on the fold/unfold process for the lower-level convolution calculations.\n",
    "def make_random_square_masks(inputs, mask_size):\n",
    "    ##### TODO: Double check that this properly covers the whole range of values. :'( :')\n",
    "    if mask_size == 0:\n",
    "        return None # no need to cutout or do anything like that since the patch_size is set to 0\n",
    "    is_even = int(mask_size % 2 == 0)\n",
    "    in_shape = inputs.shape\n",
    "\n",
    "    # seed centers of squares to cutout boxes from, in one dimension each\n",
    "    mask_center_y = torch.empty(in_shape[0], dtype=torch.long, device=inputs.device).random_(mask_size//2-is_even, in_shape[-2]-mask_size//2-is_even)\n",
    "    mask_center_x = torch.empty(in_shape[0], dtype=torch.long, device=inputs.device).random_(mask_size//2-is_even, in_shape[-1]-mask_size//2-is_even)\n",
    "\n",
    "    # measure distance, using the center as a reference point\n",
    "    to_mask_y_dists = torch.arange(in_shape[-2], device=inputs.device).view(1, 1, in_shape[-2], 1) - mask_center_y.view(-1, 1, 1, 1)\n",
    "    to_mask_x_dists = torch.arange(in_shape[-1], device=inputs.device).view(1, 1, 1, in_shape[-1]) - mask_center_x.view(-1, 1, 1, 1)\n",
    "\n",
    "    to_mask_y = (to_mask_y_dists >= (-(mask_size // 2) + is_even)) * (to_mask_y_dists <= mask_size // 2)\n",
    "    to_mask_x = (to_mask_x_dists >= (-(mask_size // 2) + is_even)) * (to_mask_x_dists <= mask_size // 2)\n",
    "\n",
    "    final_mask = to_mask_y * to_mask_x ## Turn (y by 1) and (x by 1) boolean masks into (y by x) masks through multiplication. Their intersection is square, hurray! :D\n",
    "\n",
    "    return final_mask\n",
    "\n",
    "def batch_crop(inputs, crop_size):\n",
    "    with torch.no_grad():\n",
    "        crop_mask_batch = make_random_square_masks(inputs, crop_size)\n",
    "        cropped_batch = torch.masked_select(inputs, crop_mask_batch).view(inputs.shape[0], inputs.shape[1], crop_size, crop_size)\n",
    "        return cropped_batch\n",
    "\n",
    "def batch_flip_lr(batch_images, flip_chance=.5):\n",
    "    with torch.no_grad():\n",
    "        # TODO: Is there a more elegant way to do this? :') :'((((\n",
    "        return torch.where(torch.rand_like(batch_images[:, 0, 0, 0].view(-1, 1, 1, 1)) < flip_chance, torch.flip(batch_images, (-1,)), batch_images)\n",
    "\n",
    "# TODO: Could we jit this in the (more distant) future? :)\n",
    "@torch.no_grad()\n",
    "def get_batches(data_dict, key, batchsize, cutmix=False, cutmix_size=None):\n",
    "    num_epoch_examples = len(data_dict[key]['images'])\n",
    "    shuffled = torch.randperm(num_epoch_examples, device='cuda')\n",
    "    crop_size = 32\n",
    "    ## Here, we prep the dataset by applying all data augmentations in batches ahead of time before each epoch, then we return an iterator below\n",
    "    ## that iterates in chunks over with a random derangement (i.e. shuffled indices) of the individual examples. So we get perfectly-shuffled\n",
    "    ## batches (which skip the last batch if it's not a full batch), but everything seems to be (and hopefully is! :D) properly shuffled. :)\n",
    "    if key == 'train':\n",
    "        images = batch_crop(data_dict[key]['images'], crop_size) # TODO: hardcoded image size for now?\n",
    "        images = batch_flip_lr(images)\n",
    "        targets = data_dict[key][\"targets\"]\n",
    "        if cutmix:\n",
    "            images, targets = batch_cutmix(images, data_dict[key]['targets'], patch_size=cutmix_size)\n",
    "    else:\n",
    "        images = data_dict[key]['images']\n",
    "        targets = data_dict[key]['targets']\n",
    "\n",
    "    # # Send the images to an (in beta) channels_last to help improve tensor core occupancy (and reduce NCHW <-> NHWC thrash) during training\n",
    "    # images = images.to(memory_format=torch.channels_last)\n",
    "    for idx in range(num_epoch_examples // batchsize):\n",
    "        if not (idx+1)*batchsize > num_epoch_examples: ## Use the shuffled randperm to assemble individual items into a minibatch\n",
    "            yield images.index_select(0, shuffled[idx*batchsize:(idx+1)*batchsize]), \\\n",
    "                  targets.index_select(0, shuffled[idx*batchsize:(idx+1)*batchsize]) ## Each item is only used/accessed by the network once per epoch. :D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|█████████████████████████▉| 49920/50000 [00:09<00:00, 5128.98img/s, Loss=2.07, Acc=32.6]\n",
      "Eval: 100%|██████████████████████████▉| 9984/10000 [00:00<00:00, 24533.77img/s, Loss=1.57, Acc=41.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|█████████████████████████▉| 49920/50000 [00:07<00:00, 6327.68img/s, Loss=1.45, Acc=47.3]\n",
      "Eval: 100%|███████████████████████████▉| 9984/10000 [00:00<00:00, 24608.52img/s, Loss=1.3, Acc=53.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|█████████████████████████▉| 49920/50000 [00:07<00:00, 6316.52img/s, Loss=1.25, Acc=55.4]\n",
      "Eval: 100%|███████████████████████████▉| 9984/10000 [00:00<00:00, 24337.98img/s, Loss=1.2, Acc=56.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|█████████████████████████▉| 49920/50000 [00:07<00:00, 6311.78img/s, Loss=1.11, Acc=60.4]\n",
      "Eval: 100%|██████████████████████████▉| 9984/10000 [00:00<00:00, 24501.77img/s, Loss=1.02, Acc=64.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|█████████████████████████▉| 49920/50000 [00:07<00:00, 6296.33img/s, Loss=1.02, Acc=64.1]\n",
      "Eval: 100%|██████████████████████████▉| 9984/10000 [00:00<00:00, 23801.72img/s, Loss=0.92, Acc=67.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|████████████████████████▉| 49920/50000 [00:07<00:00, 6310.99img/s, Loss=0.947, Acc=66.7]\n",
      "Eval: 100%|█████████████████████████▉| 9984/10000 [00:00<00:00, 23547.84img/s, Loss=0.895, Acc=68.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|████████████████████████▉| 49920/50000 [00:07<00:00, 6284.78img/s, Loss=0.905, Acc=68.4]\n",
      "Eval: 100%|█████████████████████████▉| 9984/10000 [00:00<00:00, 24346.56img/s, Loss=0.892, Acc=69.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|████████████████████████▉| 49920/50000 [00:07<00:00, 6273.98img/s, Loss=0.867, Acc=69.9]\n",
      "Eval: 100%|██████████████████████████▉| 9984/10000 [00:00<00:00, 24431.10img/s, Loss=0.87, Acc=69.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|████████████████████████▉| 49920/50000 [00:07<00:00, 6275.78img/s, Loss=0.839, Acc=70.8]\n",
      "Eval: 100%|█████████████████████████▉| 9984/10000 [00:00<00:00, 24254.67img/s, Loss=0.862, Acc=70.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████████████████████▉| 49920/50000 [00:07<00:00, 6288.95img/s, Loss=0.808, Acc=72]\n",
      "Eval: 100%|█████████████████████████▉| 9984/10000 [00:00<00:00, 24343.47img/s, Loss=0.788, Acc=72.5]\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(total=len(data[\"train\"][\"images\"]), desc=\"Train\", unit=\"img\", ncols=100)\n",
    "    for batch_idx, (inputs, targets) in enumerate(get_batches(data, \"train\", batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        pbar.update(len(inputs))\n",
    "        pbar.set_postfix({\"Loss\": train_loss/(batch_idx+1), \"Acc\": 100.*correct/total})\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "def eval(epoch):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(total=len(data[\"eval\"][\"images\"]), desc=\"Eval\", unit=\"img\", ncols=100)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(get_batches(data, \"eval\", batch_size)):\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.update(len(inputs))\n",
    "            pbar.set_postfix({\"Loss\": test_loss/(batch_idx+1), \"Acc\": 100.*correct/total})\n",
    "        pbar.close()\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    eval(epoch)\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
