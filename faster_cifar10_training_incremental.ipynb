{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Mean: ['0.5071', '0.4865', '0.4409']\n",
      "Std: ['0.2673', '0.2564', '0.2762']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# reproducibility\n",
    "seed = 1993\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "batch_size = 128\n",
    "lr = 0.1\n",
    "\n",
    "data_dir = \"/home/studio-lab-user/CIL_Survey/data\"\n",
    "train_dataset_gpu = {}\n",
    "eval_dataset_gpu = {}\n",
    "\n",
    "# dataset\n",
    "train = torchvision.datasets.CIFAR100(root=data_dir, download=True, transform=transforms.ToTensor())\n",
    "eval = torchvision.datasets.CIFAR100(root=data_dir, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# move dataset to gpu\n",
    "train_dataset_gpu_loader = torch.utils.data.DataLoader(train, batch_size=len(train), drop_last=True,\n",
    "                                            shuffle=True, num_workers=2, persistent_workers=False)\n",
    "eval_dataset_gpu_loader = torch.utils.data.DataLoader(eval, batch_size=len(eval), drop_last=True,\n",
    "                                            shuffle=False, num_workers=1, persistent_workers=False)\n",
    "train_dataset_gpu['images'], train_dataset_gpu['targets'] = [item.to(device=\"cuda\", non_blocking=True) for item in next(iter(train_dataset_gpu_loader))]\n",
    "eval_dataset_gpu['images'],  eval_dataset_gpu['targets']  = [item.to(device=\"cuda\", non_blocking=True) for item in next(iter(eval_dataset_gpu_loader)) ]\n",
    "\n",
    "# normalization\n",
    "train_cifar_std, train_cifar_mean = torch.std_mean(train_dataset_gpu['images'], dim=(0, 2, 3)) \n",
    "print(f\"Mean: {[f'{x:.4f}' for x in train_cifar_mean.tolist()]}\")\n",
    "print(f\"Std: {[f'{x:.4f}' for x in train_cifar_std.tolist()]}\")\n",
    "def batch_normalize_images(input_images, mean, std):\n",
    "    return (input_images - mean.view(1, -1, 1, 1)) / std.view(1, -1, 1, 1)\n",
    "batch_normalize_images = partial(batch_normalize_images, mean=train_cifar_mean, std=train_cifar_std)\n",
    "train_dataset_gpu['images'] = batch_normalize_images(train_dataset_gpu['images'])\n",
    "eval_dataset_gpu['images']  = batch_normalize_images(eval_dataset_gpu['images'])\n",
    "\n",
    "data = {\n",
    "        'train': train_dataset_gpu,\n",
    "        'eval': eval_dataset_gpu\n",
    "    }\n",
    "\n",
    "# pad images for later random cropping\n",
    "pad_amount = 4\n",
    "data['train']['images'] = F.pad(data['train']['images'], (pad_amount,)*4, 'reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms are:\n",
    "# random crop\n",
    "# random horizontal flip\n",
    "\n",
    "from convs.cifar_resnet import resnet32\n",
    "\n",
    "# net = resnet32()\n",
    "net = torchvision.models.resnet18()\n",
    "net.to(device);  \n",
    "# net = IncrementalNet(\"resnet32\", pretrained=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is actually (I believe) a pretty clean implementation of how to do something like this, since shifted-square masks unique to each depth-channel can actually be rather\n",
    "## tricky in practice. That said, if there's a better way, please do feel free to submit it! This can be one of the harder parts of the code to understand (though I personally get\n",
    "## stuck on the fold/unfold process for the lower-level convolution calculations.\n",
    "def make_random_square_masks(inputs, mask_size):\n",
    "    ##### TODO: Double check that this properly covers the whole range of values. :'( :')\n",
    "    if mask_size == 0:\n",
    "        return None # no need to cutout or do anything like that since the patch_size is set to 0\n",
    "    is_even = int(mask_size % 2 == 0)\n",
    "    in_shape = inputs.shape\n",
    "\n",
    "    # seed centers of squares to cutout boxes from, in one dimension each\n",
    "    mask_center_y = torch.empty(in_shape[0], dtype=torch.long, device=inputs.device).random_(mask_size//2-is_even, in_shape[-2]-mask_size//2-is_even)\n",
    "    mask_center_x = torch.empty(in_shape[0], dtype=torch.long, device=inputs.device).random_(mask_size//2-is_even, in_shape[-1]-mask_size//2-is_even)\n",
    "\n",
    "    # measure distance, using the center as a reference point\n",
    "    to_mask_y_dists = torch.arange(in_shape[-2], device=inputs.device).view(1, 1, in_shape[-2], 1) - mask_center_y.view(-1, 1, 1, 1)\n",
    "    to_mask_x_dists = torch.arange(in_shape[-1], device=inputs.device).view(1, 1, 1, in_shape[-1]) - mask_center_x.view(-1, 1, 1, 1)\n",
    "\n",
    "    to_mask_y = (to_mask_y_dists >= (-(mask_size // 2) + is_even)) * (to_mask_y_dists <= mask_size // 2)\n",
    "    to_mask_x = (to_mask_x_dists >= (-(mask_size // 2) + is_even)) * (to_mask_x_dists <= mask_size // 2)\n",
    "\n",
    "    final_mask = to_mask_y * to_mask_x ## Turn (y by 1) and (x by 1) boolean masks into (y by x) masks through multiplication. Their intersection is square, hurray! :D\n",
    "\n",
    "    return final_mask\n",
    "\n",
    "def batch_crop(inputs, crop_size):\n",
    "    with torch.no_grad():\n",
    "        crop_mask_batch = make_random_square_masks(inputs, crop_size)\n",
    "        cropped_batch = torch.masked_select(inputs, crop_mask_batch).view(inputs.shape[0], inputs.shape[1], crop_size, crop_size)\n",
    "        return cropped_batch\n",
    "\n",
    "def batch_flip_lr(batch_images, flip_chance=.5):\n",
    "    with torch.no_grad():\n",
    "        # TODO: Is there a more elegant way to do this? :') :'((((\n",
    "        return torch.where(torch.rand_like(batch_images[:, 0, 0, 0].view(-1, 1, 1, 1)) < flip_chance, torch.flip(batch_images, (-1,)), batch_images)\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_batches(data_dict, key, batchsize, indices, cutmix=False, cutmix_size=None):\n",
    "    # select subset of class indices \n",
    "    if indices is not None:\n",
    "        indices = torch.tensor(indices, device=device)\n",
    "        images, targets = data_dict[key][\"images\"], data_dict[key][\"targets\"] \n",
    "        samples = torch.isin(targets, indices)\n",
    "        images, targets = images[samples], targets[samples]\n",
    "        assert len(images) == len(targets)\n",
    "\n",
    "    num_epoch_examples = len(images)\n",
    "    shuffled = torch.randperm(num_epoch_examples, device=device)\n",
    "    crop_size = 32\n",
    "\n",
    "    ## Here, we prep the dataset by applying all data augmentations in batches ahead of time before each epoch, then we return an iterator below\n",
    "    ## that iterates in chunks over with a random derangement (i.e. shuffled indices) of the individual examples. So we get perfectly-shuffled\n",
    "    ## batches (which skip the last batch if it's not a full batch), but everything seems to be (and hopefully is! :D) properly shuffled. :)\n",
    "    if key == 'train':\n",
    "        images = batch_crop(images, crop_size) # TODO: hardcoded image size for now?\n",
    "        images = batch_flip_lr(images)\n",
    "        if cutmix:\n",
    "            images, targets = batch_cutmix(images, targets, patch_size=cutmix_size)\n",
    "\n",
    "    # # Send the images to an (in beta) channels_last to help improve tensor core occupancy (and reduce NCHW <-> NHWC thrash) during training\n",
    "    # images = images.to(memory_format=torch.channels_last)\n",
    "    for idx in range(num_epoch_examples // batchsize):\n",
    "        if not (idx+1)*batchsize > num_epoch_examples: ## Use the shuffled randperm to assemble individual items into a minibatch\n",
    "            yield images.index_select(0, shuffled[idx*batchsize:(idx+1)*batchsize]), \\\n",
    "                  targets.index_select(0, shuffled[idx*batchsize:(idx+1)*batchsize]) ## Each item is only used/accessed by the network once per epoch. :D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = range(5)\n",
    "# indices = torch.tensor(indices, device=device)\n",
    "# images, targets = data[\"eval\"][\"images\"], data[\"eval\"][\"targets\"] \n",
    "# samples = torch.isin(targets, indices)\n",
    "# images, targets = images[samples], targets[samples]\n",
    "\n",
    "# assert len(images) == len(targets)\n",
    "\n",
    "# num_epoch_examples = len(images)\n",
    "# print(num_epoch_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# epochs = 200\n",
    "# lr = 0.1\n",
    "# weight_decay = 0.0005\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), momentum=0.9, lr=lr, weight_decay=weight_decay)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "# epochs = 80\n",
    "# lrate = 0.1\n",
    "# milestones = [40, 70]\n",
    "# lrate_decay = 0.1\n",
    "# batch_size = 128\n",
    "# weight_decay = 2e-4\n",
    "# optimizer = optim.SGD(net.parameters(), lr=lrate, momentum=0.9, weight_decay=weight_decay)\n",
    "# scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=milestones, gamma=lrate_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (inputs, targets) in enumerate(get_batches(data, \"train\", batch_size, indices)):\n",
    "#     out = net(inputs)\n",
    "#     print(out.keys())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch, indices, optimizer, first_task=True):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # pbar = tqdm(total=2500, desc=\"Train\", unit=\"img\", ncols=100)\n",
    "    for batch_idx, (inputs, targets) in enumerate(get_batches(data, \"train\", batch_size, indices)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets) if first_task else criterion(outputs[:, min(indices):], targets - min(indices))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += len(targets)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # pbar.update(len(inputs))\n",
    "    # pbar.set_postfix({\"Train Loss\": train_loss/(batch_idx+1), \"Train Acc\": 100.*correct/total})\n",
    "    # pbar.close()\n",
    "    return train_loss/(batch_idx + 1), 100.*correct/total\n",
    "\n",
    "\n",
    "def eval(epoch, indices):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # pbar = tqdm(total=500, desc=\"Eval\", unit=\"img\", ncols=100)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(get_batches(data, \"eval\", batch_size, indices)):\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # pbar.update(len(inputs))\n",
    "        # pbar.set_postfix({\"Eval Loss\": test_loss/(batch_idx+1), \"Eval Acc\": 100.*correct/total})\n",
    "        # pbar.close()\n",
    "\n",
    "    return test_loss/(batch_idx + 1), 100.*correct/total\n",
    "\n",
    "\n",
    "increment = 5\n",
    "total_classes = 100 \n",
    "current_classes = 0 \n",
    "feature_dim = 512\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_epochs = 200\n",
    "lr = 0.1\n",
    "weight_decay = 0.0005\n",
    "\n",
    "rest_epochs = 80\n",
    "lrate = 0.1\n",
    "milestones = [40, 70]\n",
    "lrate_decay = 0.1\n",
    "weight_decay = 2e-4\n",
    "\n",
    "def incremental_train():\n",
    "    print(f\"Training on {current_classes} + {increment}\")\n",
    "    indices = range(current_classes, current_classes + increment)\n",
    "    \n",
    "    # update linear classifier\n",
    "    new_fc = nn.Linear(feature_dim, current_classes + increment, device=\"cuda\")\n",
    "    nn.init.kaiming_uniform_(new_fc.weight, nonlinearity='linear')\n",
    "    nn.init.constant_(new_fc.bias, 0)\n",
    "    if current_classes != 0:\n",
    "        old_fc = net.fc\n",
    "        new_fc.weight.data[:current_classes] = old_fc.weight\n",
    "        new_fc.bias.data[:current_classes] = old_fc.bias\n",
    "    net.fc = new_fc\n",
    "\n",
    "    # select optimize and scheduler\n",
    "    if current_classes > 0:\n",
    "        epochs = rest_epochs\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lrate, momentum=0.9, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=milestones, gamma=lrate_decay)\n",
    "    else: \n",
    "        epochs = init_epochs\n",
    "        optimizer = optim.SGD(net.parameters(), momentum=0.9, lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "\n",
    "    pbar = tqdm(range(epochs), ncols=150, unit=\"epoch\")\n",
    "    for epoch in pbar:\n",
    "        tloss, tacc = train(epoch, indices, optimizer, first_task=current_classes == 0)\n",
    "        eloss, eacc = eval(epoch, indices)\n",
    "        scheduler.step()\n",
    "        pbar.set_postfix({\"Train Loss\": tloss, \"Train Acc\": tacc, \"Eval Loss\": eloss, \"Eval Acc\": eacc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 0 + 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [01:44<00:00,  1.92epoch/s, Train Loss=0.00674, Train Acc=99.8, Eval Loss=1.11, Eval Acc=81.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 5 + 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:41<00:00,  1.94epoch/s, Train Loss=0.0208, Train Acc=97.8, Eval Loss=0.901, Eval Acc=79.4]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    incremental_train()\n",
    "    current_classes += increment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
