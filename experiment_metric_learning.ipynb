{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿How well does a metric learning approach do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# reproducibility\n",
    "seed = 1993\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Mean: ['0.5071', '0.4865', '0.4409']\n",
      "Std: ['0.2673', '0.2564', '0.2762']\n"
     ]
    }
   ],
   "source": [
    "train_dataset_gpu = {}\n",
    "eval_dataset_gpu = {}\n",
    "\n",
    "# dataset\n",
    "train = torchvision.datasets.CIFAR100(root=data_dir, download=True, transform=transforms.ToTensor())\n",
    "eval = torchvision.datasets.CIFAR100(root=data_dir, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# move dataset to gpu\n",
    "train_dataset_gpu_loader = torch.utils.data.DataLoader(train, batch_size=len(train), drop_last=True,\n",
    "                                            shuffle=True, num_workers=2, persistent_workers=False)\n",
    "eval_dataset_gpu_loader = torch.utils.data.DataLoader(eval, batch_size=len(eval), drop_last=True,\n",
    "                                            shuffle=False, num_workers=1, persistent_workers=False)\n",
    "train_dataset_gpu['images'], train_dataset_gpu['targets'] = [item.to(device=\"cuda\", non_blocking=True) for item in next(iter(train_dataset_gpu_loader))]\n",
    "eval_dataset_gpu['images'],  eval_dataset_gpu['targets']  = [item.to(device=\"cuda\", non_blocking=True) for item in next(iter(eval_dataset_gpu_loader)) ]\n",
    "\n",
    "# normalize images\n",
    "train_cifar_std, train_cifar_mean = torch.std_mean(train_dataset_gpu['images'], dim=(0, 2, 3)) \n",
    "print(f\"Mean: {[f'{x:.4f}' for x in train_cifar_mean.tolist()]}\")\n",
    "print(f\"Std: {[f'{x:.4f}' for x in train_cifar_std.tolist()]}\")\n",
    "def batch_normalize_images(input_images, mean, std):\n",
    "    return (input_images - mean.view(1, -1, 1, 1)) / std.view(1, -1, 1, 1)\n",
    "batch_normalize_images = partial(batch_normalize_images, mean=train_cifar_mean, std=train_cifar_std)\n",
    "train_dataset_gpu['images'] = batch_normalize_images(train_dataset_gpu['images'])\n",
    "eval_dataset_gpu['images']  = batch_normalize_images(eval_dataset_gpu['images'])\n",
    "\n",
    "data = {\n",
    "        'train': train_dataset_gpu,\n",
    "        'eval': eval_dataset_gpu\n",
    "    }\n",
    "\n",
    "# pad images for later random cropping\n",
    "pad_amount = 4\n",
    "data['train']['images'] = F.pad(data['train']['images'], (pad_amount,)*4, 'reflect')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric based data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from batch_transforms import batch_crop, batch_flip_lr\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_batches(data_dict, key, batchsize, indices=range(100)):\n",
    "    # select subset of class indices \n",
    "    indices = torch.tensor(indices, device=device)\n",
    "    images, targets = data_dict[key][\"images\"], data_dict[key][\"targets\"] \n",
    "    samples = torch.isin(targets, indices)\n",
    "    images, targets = images[samples], targets[samples]\n",
    "    \n",
    "    assert len(images) == len(targets)\n",
    "\n",
    "    # as we are going to pair up the images, we need the size of the dataset to be even\n",
    "    if len(images) % 2 != 0:\n",
    "        images = images[:-1]\n",
    "        targets = targets[:-1]\n",
    "\n",
    "    num_epoch_examples = len(images)\n",
    "    shuffled = torch.randperm(num_epoch_examples, device=device)\n",
    "    crop_size = 32\n",
    "\n",
    "    # shuffle the dataset\n",
    "    images = images[shuffled]\n",
    "    targets = targets[shuffled]\n",
    "\n",
    "    # transforms\n",
    "    if key == 'train':\n",
    "        images = batch_crop(images, crop_size)\n",
    "        images = batch_flip_lr(images)\n",
    "\n",
    "    # pair up the dataset\n",
    "    targets = targets.reshape(num_epoch_examples // 2, 2)\n",
    "    binary_targets = torch.eq(targets[:,0], targets[:,1])\n",
    "    # we need that roughly 50% of the pairs are positive and negative\n",
    "    while binary_targets.float().mean() < 0.5:\n",
    "        # unpair the target and binary_targets\n",
    "        targets = targets.reshape(num_epoch_examples)  \n",
    "        binary_targets = torch.stack([binary_targets, binary_targets], 1).reshape(num_epoch_examples)\n",
    "        # get negative elements from negative pairs\n",
    "        neg = binary_targets == False\n",
    "        # permute them hoping some of them turn into positive pairs\n",
    "        perm = torch.randperm(len(binary_targets[neg]))\n",
    "        images[neg] = images[neg][perm]\n",
    "        targets[neg] = targets[neg][perm]\n",
    "        # re-pair the targets\n",
    "        targets = targets.reshape(num_epoch_examples // 2, 2)\n",
    "        binary_targets = torch.eq(targets[:,0], targets[:,1])\n",
    "    ## TODO: ensuring 50% distribtution takes much longer than before \n",
    "    ## without 50% -> 30 ms\n",
    "    ## with 50% -> 1 seg\n",
    "    \n",
    "    images = images.reshape(num_epoch_examples // 2, 2, 3, images.shape[-1], images.shape[-2])\n",
    "    num_epoch_examples = len(images)\n",
    "\n",
    "    for idx in range(num_epoch_examples // batchsize):\n",
    "        yield images[idx*batchsize: (idx+1)*batchsize], targets[idx*batchsize: (idx+1)*batchsize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿How do I make sure that the implementation is correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Are there any duplicated or overlapping pairs?\n",
    "    I think there are not since the pairs are selected by reshaping the original 1d-tensor of targets in a matrix with 2 rows, so if there were not any duplicates in the original tensor, then there must not be any duplicates in the pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.66 s, sys: 7.13 ms, total: 1.67 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for x, y in get_batches(data, \"train\", 128):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0.], device='cuda:0')\n",
      "tensor(0.5625, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.eq(y[:, 0], y[:, 1]).float())\n",
    "print(torch.eq(y[:, 0], y[:, 1]).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([85, 85], device='cuda:0')\n",
      "['tank', 'tank']\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "idx_to_class = {i:c for c,i in train.class_to_idx.items()}\n",
    "\n",
    "print(idx)\n",
    "display(to_pil_image(x[idx][0]))\n",
    "display(to_pil_image(x[idx][1]))\n",
    "\n",
    "print(y[idx])\n",
    "print([idx_to_class[i] for i in y[idx].tolist()])\n",
    "idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 ms, sys: 152 µs, total: 31.7 ms\n",
      "Wall time: 30.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for x, y in old_get_batches(data, \"train\", 128):\n",
    "    y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=40x40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(95, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=40x40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(79, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=40x40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=40x40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([95, 79], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "n = len(data[\"train\"][\"images\"])\n",
    "\n",
    "images_pairs = data[\"train\"][\"images\"].reshape(n // 2, 2, 3, 40, 40)\n",
    "labels_pairs  = data[\"train\"][\"targets\"].reshape(n // 2, 2)\n",
    "\n",
    "# show first and second image\n",
    "display(to_pil_image(data[\"train\"][\"images\"][0]))\n",
    "print(data[\"train\"][\"targets\"][0])\n",
    "display(to_pil_image(data[\"train\"][\"images\"][1]))\n",
    "print(data[\"train\"][\"targets\"][1])\n",
    "\n",
    "# show first pair\n",
    "display(to_pil_image(images_pairs[0][0]))\n",
    "display(to_pil_image(images_pairs[0][1]))\n",
    "print(labels_pairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement siamese network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = resnet18()\n",
    "    def forward(self, x):\n",
    "        x1, x2 = x[:, 0], x[:, 1]\n",
    "        out1 = self.conv(x1) \n",
    "        out2 = self.conv(x2) \n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(get_batches(data, \"train\", 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SiameseNetwork()\n",
    "net.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseNetwork(\n",
       "  (conv): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7721, -0.7750, -0.2479,  ..., -0.8757, -0.3601, -1.5296],\n",
       "         [-0.7030, -1.1397, -1.0125,  ...,  0.0858,  1.4796, -1.5887],\n",
       "         [ 0.2177, -0.5399, -0.1763,  ..., -0.1740, -0.5940, -0.3313],\n",
       "         ...,\n",
       "         [-0.5797, -0.2422, -1.5918,  ..., -1.9408, -0.5012, -1.9485],\n",
       "         [ 0.6935, -0.1040, -0.1168,  ..., -1.0111,  0.1526, -1.4841],\n",
       "         [ 0.0484,  0.0936, -0.9645,  ..., -0.8984, -1.2240, -0.8217]],\n",
       "        device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " tensor([[-1.3620, -1.0903, -0.1727,  ..., -1.3179, -0.8336, -2.7955],\n",
       "         [ 0.4660, -1.0332, -0.4220,  ..., -0.9287,  0.1984, -1.7302],\n",
       "         [ 0.7808, -0.6694, -0.7343,  ..., -0.2432, -0.4241, -0.7299],\n",
       "         ...,\n",
       "         [-0.4616, -1.2402, -1.6677,  ..., -0.2420, -0.6424, -1.1838],\n",
       "         [ 0.0360,  0.0763, -1.6020,  ..., -0.3390,  0.7023, -0.8393],\n",
       "         [ 0.3705,  1.0578, -0.1092,  ...,  0.5523, -0.8981, -0.8996]],\n",
       "        device='cuda:0', grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(x, y):\n",
    "    # x -> (bs, 2, ndim)\n",
    "    # y -> (bs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and eval methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
