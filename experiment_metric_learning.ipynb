{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿How well does a metric learning approach do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# reproducibility\n",
    "seed = 1993\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset_gpu = {}\n",
    "eval_dataset_gpu = {}\n",
    "\n",
    "# dataset\n",
    "train = torchvision.datasets.CIFAR100(root=data_dir, download=True, transform=transforms.ToTensor())\n",
    "eval = torchvision.datasets.CIFAR100(root=data_dir, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# move dataset to gpu\n",
    "train_dataset_gpu_loader = torch.utils.data.DataLoader(train, batch_size=len(train), drop_last=True,\n",
    "                                            shuffle=True, num_workers=2, persistent_workers=False)\n",
    "eval_dataset_gpu_loader = torch.utils.data.DataLoader(eval, batch_size=len(eval), drop_last=True,\n",
    "                                            shuffle=False, num_workers=1, persistent_workers=False)\n",
    "train_dataset_gpu['images'], train_dataset_gpu['targets'] = [item.to(device=\"cuda\", non_blocking=True) for item in next(iter(train_dataset_gpu_loader))]\n",
    "eval_dataset_gpu['images'],  eval_dataset_gpu['targets']  = [item.to(device=\"cuda\", non_blocking=True) for item in next(iter(eval_dataset_gpu_loader)) ]\n",
    "\n",
    "# normalize images\n",
    "train_cifar_std, train_cifar_mean = torch.std_mean(train_dataset_gpu['images'], dim=(0, 2, 3)) \n",
    "print(f\"Mean: {[f'{x:.4f}' for x in train_cifar_mean.tolist()]}\")\n",
    "print(f\"Std: {[f'{x:.4f}' for x in train_cifar_std.tolist()]}\")\n",
    "def batch_normalize_images(input_images, mean, std):\n",
    "    return (input_images - mean.view(1, -1, 1, 1)) / std.view(1, -1, 1, 1)\n",
    "batch_normalize_images = partial(batch_normalize_images, mean=train_cifar_mean, std=train_cifar_std)\n",
    "train_dataset_gpu['images'] = batch_normalize_images(train_dataset_gpu['images'])\n",
    "eval_dataset_gpu['images']  = batch_normalize_images(eval_dataset_gpu['images'])\n",
    "\n",
    "data = {\n",
    "        'train': train_dataset_gpu,\n",
    "        'eval': eval_dataset_gpu\n",
    "    }\n",
    "\n",
    "# pad images for later random cropping\n",
    "pad_amount = 4\n",
    "data['train']['images'] = F.pad(data['train']['images'], (pad_amount,)*4, 'reflect')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric based data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from batch_transforms import batch_crop, batch_flip_lr\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_batches(data_dict, key, batchsize, indices=range(100)):\n",
    "    # select subset of class indices \n",
    "    indices = torch.tensor(indices, device=device)\n",
    "    images, targets = data_dict[key][\"images\"], data_dict[key][\"targets\"] \n",
    "    samples = torch.isin(targets, indices)\n",
    "    images, targets = images[samples], targets[samples]\n",
    "    \n",
    "    assert len(images) == len(targets)\n",
    "\n",
    "    # as we are going to pair up the images, we need the size of the dataset to be even\n",
    "    if len(images) % 2 != 0:\n",
    "        images = images[:-1]\n",
    "        targets = targets[:-1]\n",
    "\n",
    "    num_epoch_examples = len(images)\n",
    "    shuffled = torch.randperm(num_epoch_examples, device=device)\n",
    "    crop_size = 32\n",
    "\n",
    "    # shuffle the dataset\n",
    "    images = images[shuffled]\n",
    "    targets = targets[shuffled]\n",
    "\n",
    "    # transforms\n",
    "    if key == 'train':\n",
    "        images = batch_crop(images, crop_size)\n",
    "        images = batch_flip_lr(images)\n",
    "\n",
    "    # pair up the dataset\n",
    "    targets = targets.reshape(num_epoch_examples // 2, 2)\n",
    "    binary_targets = torch.eq(targets[:,0], targets[:,1])\n",
    "    # we need that roughly 50% of the pairs are positive and negative\n",
    "    while binary_targets.float().mean() < 0.5:\n",
    "        # unpair the target and binary_targets\n",
    "        targets = targets.reshape(num_epoch_examples)  \n",
    "        binary_targets = torch.stack([binary_targets, binary_targets], 1).reshape(num_epoch_examples)\n",
    "        # get negative elements from negative pairs\n",
    "        neg = binary_targets == False\n",
    "        # permute them hoping some of them turn into positive pairs\n",
    "        perm = torch.randperm(len(binary_targets[neg]))\n",
    "        images[neg] = images[neg][perm]\n",
    "        targets[neg] = targets[neg][perm]\n",
    "        # re-pair the targets\n",
    "        targets = targets.reshape(num_epoch_examples // 2, 2)\n",
    "        binary_targets = torch.eq(targets[:,0], targets[:,1])\n",
    "    ## TODO: ensuring 50% distribtution takes much longer than before \n",
    "    ## without 50% -> 30 ms\n",
    "    ## with 50% -> 1 seg\n",
    "    \n",
    "    images = images.reshape(num_epoch_examples // 2, 2, 3, images.shape[-1], images.shape[-2])\n",
    "    num_epoch_examples = len(images)\n",
    "\n",
    "    for idx in range(num_epoch_examples // batchsize):\n",
    "        yield images[idx*batchsize: (idx+1)*batchsize, 0], images[idx*batchsize: (idx+1)*batchsize, 1],  binary_targets[idx*batchsize: (idx+1)*batchsize].int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿How do I make sure that the implementation is correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Are there any duplicated or overlapping pairs?\n",
    "    I think there are not since the pairs are selected by reshaping the original 1d-tensor of targets in a matrix with 2 rows, so if there were not any duplicates in the original tensor, then there must not be any duplicates in the pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.64 s, sys: 4.89 ms, total: 1.64 s\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for x1, x2, y in get_batches(data, \"train\", 128):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(x1.shape)\n",
    "print(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([59, 59], device='cuda:0')\n",
      "['pine_tree', 'pine_tree']\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "idx_to_class = {i:c for c,i in train.class_to_idx.items()}\n",
    "\n",
    "print(idx)\n",
    "display(to_pil_image(x1[idx]))\n",
    "display(to_pil_image(x2[idx]))\n",
    "\n",
    "print(y[idx])\n",
    "# print([idx_to_class[i] for i in y[idx].tolist()])\n",
    "idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 ms, sys: 152 µs, total: 31.7 ms\n",
      "Wall time: 30.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for x, y in old_get_batches(data, \"train\", 128):\n",
    "    y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=40x40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(95, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=40x40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(79, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=40x40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=40x40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([95, 79], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "n = len(data[\"train\"][\"images\"])\n",
    "\n",
    "images_pairs = data[\"train\"][\"images\"].reshape(n // 2, 2, 3, 40, 40)\n",
    "labels_pairs = data[\"train\"][\"targets\"].reshape(n // 2, 2)\n",
    "\n",
    "# show first and second image\n",
    "display(to_pil_image(data[\"train\"][\"images\"][0]))\n",
    "print(data[\"train\"][\"targets\"][0])\n",
    "display(to_pil_image(data[\"train\"][\"images\"][1]))\n",
    "print(data[\"train\"][\"targets\"][1])\n",
    "\n",
    "# show first pair\n",
    "display(to_pil_image(images_pairs[0][0]))\n",
    "display(to_pil_image(images_pairs[0][1]))\n",
    "print(labels_pairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement siamese network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, y = next(get_batches(data, \"train\", 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print(x1.shape)\n",
    "print(x2.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = resnet18()\n",
    "        self.ndim = self.conv.fc.in_features\n",
    "        self.conv = nn.Sequential(*list(resnet18().children())[:-1])\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.ndim, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.Linear(256, 2),\n",
    "        )\n",
    "     \n",
    "    def forward_once(self, x):\n",
    "        x = self.conv(x)  # (bs, ndim, 1, 1)\n",
    "        x = torch.flatten(x, 1)  # (bs, ndim)\n",
    "        x = self.fc(x)  # (bs, 2)\n",
    "        return x \n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)  # (bs, 2)\n",
    "        output2 = self.forward_once(input2)  # (bs, 2)\n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SiameseNetwork()\n",
    "net.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2]) torch.Size([128, 2])\n"
     ]
    }
   ],
   "source": [
    "out1, out2 = net(x1, x2)\n",
    "print(out1.shape, out2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Mechanism\n",
    "\n",
    "f() -> (x, y)\n",
    "\n",
    "1. Calculate mean embedding of each class in the dataset.\n",
    "2. x -> d(x, mu_i) -> min d(x, mu_i) 1-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Contrastive Loss Function\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "      # Calculate the euclidean distance and calculate the contrastive loss\n",
    "      euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)\n",
    "      loss_contrastive = torch.mean((1-label) * euclidean_distance**2 +\n",
    "                                    (label) * torch.clamp(self.margin - euclidean_distance, min=0.0)**2)\n",
    "\n",
    "\n",
    "      return loss_contrastive    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and eval methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_transforms import get_batches\n",
    "\n",
    "# training\n",
    "def train(optimizer, task):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    indices = range(increment * task, increment * (task + 1))\n",
    "    for batch_idx, (inputs1, inputs2, targets) in enumerate(get_batches(data, \"train\", batch_size, indices=indices)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs1, outputs2 = net(inputs1, inputs2)\n",
    "        loss = criterion(outputs1, outputs2, targets) if task == 0 else criterion(outputs[:, task * increment:], targets - task * increment)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += len(targets)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return train_loss/(batch_idx + 1), 100.*correct/total\n",
    "\n",
    "def eval(from_task, to_task):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    indices = range(from_task * increment, (to_task+1) * increment)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(get_batches(data, \"eval\", batch_size, indices=indices)):\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += len(targets)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        return test_loss/(batch_idx + 1), 100.*correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the embedding with t-sne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
