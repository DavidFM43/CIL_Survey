{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finetuning strategy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment information**\n",
    "\n",
    "- dataset: cifar100\n",
    "- shuffle: True\n",
    "- init_cls: 5\n",
    "- increment: 5\n",
    "- convnet_type: resnet32\n",
    "- seed: 1993"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sets seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "seed = 1993\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from utils.data_manager import DataManager\n",
    "\n",
    "data_manager = DataManager(dataset_name=\"cifar100\", shuffle=True, seed=seed, init_cls=5, increment=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Maybe optimize transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Train data shape: (50000, 32, 32, 3)\n",
      "Test data shape: (10000, 32, 32, 3)\n",
      "Train transforms: [RandomCrop(size=(32, 32), padding=4), RandomHorizontalFlip(p=0.5), ColorJitter(brightness=(0.7529411764705882, 1.2470588235294118), contrast=None, saturation=None, hue=None)]\n",
      "Test transforms: []\n",
      "Common transforms: [ToTensor(), Normalize(mean=(0.5071, 0.4867, 0.4408), std=(0.2675, 0.2565, 0.2761))]\n"
     ]
    }
   ],
   "source": [
    "print(type(data_manager._train_data))\n",
    "print(\"Train data shape:\", data_manager._train_data.shape)\n",
    "print(\"Test data shape:\", data_manager._test_data.shape)\n",
    "\n",
    "print(\"Train transforms:\", data_manager._train_trsf)\n",
    "print(\"Test transforms:\", data_manager._test_trsf)\n",
    "print(\"Common transforms:\", data_manager._common_trsf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model strategy       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import factory\n",
    "\n",
    "model_args = {\"convnet_type\": \"resnet32\", \"skip\": False, \"memory_size\": 200, \"device\": [torch.device(\"cuda:0\"), torch.device(\"cuda:1\")]}\n",
    "model = factory.get_model(\"finetune\", args=model_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncrementalNet(\n",
       "  (convnet): CifarResNet(\n",
       "    (conv_1_3x3): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (stage_1): Sequential(\n",
       "      (0): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stage_2): Sequential(\n",
       "      (0): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): DownsampleA(\n",
       "          (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stage_3): Sequential(\n",
       "      (0): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): DownsampleA(\n",
       "          (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): ResNetBasicblock(\n",
       "        (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `model.incremental_train()` for the first task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 2500\n",
      "Length of datalaoder: 20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "model._network.update_fc(5)\n",
    "model._total_classes = 5\n",
    "batch_size = 128\n",
    "num_workers = 8\n",
    "\n",
    "# setup datasets and dataloaders\n",
    "train_dataset = data_manager.get_dataset(\n",
    "    np.arange(model._known_classes, model._total_classes),\n",
    "    source=\"train\",\n",
    "    mode=\"train\",\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, persistent_workers=True, pin_memory=True\n",
    ")\n",
    "test_dataset = data_manager.get_dataset(\n",
    "    np.arange(0, model._total_classes), source=\"test\", mode=\"test\"\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    ")\n",
    "\n",
    "if len(model._multiple_gpus) > 1:\n",
    "    model._network = nn.DataParallel(model._network, model._multiple_gpus)\n",
    "\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of datalaoder:\", len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._cur_task = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we will only focus on the first stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import logging\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "def tensor2numpy(x):\n",
    "    return x.cpu().data.numpy() if x.is_cuda else x.data.numpy()\n",
    "\n",
    "init_epoch = 200\n",
    "init_lr = 0.1\n",
    "init_milestones = [60, 120, 170]\n",
    "init_lr_decay = 0.1\n",
    "init_weight_decay = 0.0005\n",
    "\n",
    "epochs = 80\n",
    "lrate = 0.1\n",
    "milestones = [40, 70]\n",
    "lrate_decay = 0.1\n",
    "weight_decay = 2e-4\n",
    "\n",
    "\n",
    "model._network.to(model._device)\n",
    "if model._cur_task == 0:\n",
    "    # setup optimizer and scheduler\n",
    "    optimizer = optim.SGD(\n",
    "        model._network.parameters(),\n",
    "        momentum=0.9,\n",
    "        lr=init_lr,\n",
    "        weight_decay=init_weight_decay,\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=init_epoch,\n",
    "    )  \n",
    "\n",
    "    # prog_bar = tqdm(range(init_epoch))\n",
    "    prog_bar = tqdm(range(20))\n",
    "    for _, epoch in enumerate(prog_bar):\n",
    "        model._network.train()\n",
    "        losses = 0.0\n",
    "        correct, total = 0, 0\n",
    "        for i, (_, inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(model._device), targets.to(model._device)\n",
    "        #     logits = model._network(inputs)[\"logits\"]\n",
    "\n",
    "        #     loss = F.cross_entropy(logits, targets)\n",
    "        #     optimizer.zero_grad()\n",
    "        #     loss.backward()\n",
    "        #     optimizer.step()\n",
    "        #     losses += loss.item()\n",
    "\n",
    "        #     _, preds = torch.max(logits, dim=1)\n",
    "        #     correct += preds.eq(targets.expand_as(preds)).cpu().sum()\n",
    "        #     total += len(targets)\n",
    "\n",
    "        # scheduler.step()\n",
    "        # train_acc = np.around(tensor2numpy(correct) * 100 / total, decimals=2)\n",
    "\n",
    "        # if epoch % 5 == 0:\n",
    "        #     info = \"Task {}, Epoch {}/{} => Loss {:.3f}, Train_accy {:.2f}\".format(\n",
    "        #         model._cur_task,\n",
    "        #         epoch + 1,\n",
    "        #         init_epoch,\n",
    "        #         losses / len(train_loader),\n",
    "        #         train_acc,\n",
    "        #     )\n",
    "        # else:\n",
    "        #     test_acc = model._compute_accuracy(model._network, test_loader)\n",
    "        #     info = \"Task {}, Epoch {}/{} => Loss {:.3f}, Train_accy {:.2f}, Test_accy {:.2f}\".format(\n",
    "        #         model._cur_task,\n",
    "        #         epoch + 1,\n",
    "        #         init_epoch,\n",
    "        #         losses / len(train_loader),\n",
    "        #         train_acc,\n",
    "        #         test_acc,\n",
    "        #     )\n",
    "        # prog_bar.set_description(info)\n",
    "\n",
    "    # logging.info(info)\n",
    "\n",
    "    # # save checkpoint for fair comparison & save runing time\n",
    "    # test_acc = model._compute_accuracy(model._network, test_loader)\n",
    "    # model.save_checkpoint(test_acc)\n",
    "    # logging.info(\"Save checkpoint successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(model._multiple_gpus) > 1:\n",
    "    model._network = model._network.module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
